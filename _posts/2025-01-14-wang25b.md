---
title: Multi-Scale Dual-Attention Unfolding Network for Compressed Sensing Image Reconstruction
booktitle: Proceedings of the 16th Asian Conference on Machine Learning
year: '2025'
volume: '260'
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: https://raw.githubusercontent.com/mlresearch/v260/main/assets/wang25b/wang25b.pdf
url: https://proceedings.mlr.press/v260/wang25b.html
openreview: ny6N9etKUn
abstract: 'Deep Unfolding Networks have emerged as a prominent strategy in compressed
  sensing image reconstruction, effectively merging optimization techniques with deep
  learning through end-to-end training of truncated inferences. Despite their advantages,
  these algorithms generally require extensive iterations and parameters, potentially
  limited by storage capacity. Additionally, the image-level transmission at each
  iterative step does not optimally harness the inter-scale feature information available.
  To address these issues, we introduce a novel approach in this paper: the $\textbf{M}$ulti-$\textbf{S}$cale
  $\textbf{D}$ual-$\textbf{A}$ttention $\textbf{U}$nfolding $\textbf{N}$etwork ($\textbf{MSDAUN}$)
  for compressed sensing image reconstruction. We propose a cross-stage multi-scale
  deep reconstruction module $\textbf{D}$ as an iterative process, which is composed
  of multiple attention sub-modules. These include Cross Attention Transformer($\textbf{CAT}$)
  Modules that enhance the reconstruction with multi-channel inertia, thereby facilitating
  feature-level transmission and robust information exchange. Concurrently, Texture
  Attention Transformer($\textbf{TAT}$) Modules are designed to meticulously extract
  salient reconstruction information, subsequently channeling it into the texture
  path to effectuate the precise prediction of textural regions, thereby contributing
  to the meticulous restoration of textural details.  Our comprehensive experimental
  evaluation across diverse datasets confirms that MSDAUN surpasses existing state-of-the-art
  methods. This work presents significant potential for further advancements and applications
  in inverse imaging problems and optimization models.'
layout: inproceedings
issn: 2640-3498
id: wang25b
tex_title: Multi-Scale Dual-Attention Unfolding Network for Compressed Sensing Image
  Reconstruction
firstpage: 207
lastpage: 222
page: 207-222
order: 207
cycles: false
bibtex_editor: Nguyen, Vu and Lin, Hsuan-Tien
editor:
- given: Vu
  family: Nguyen
- given: Hsuan-Tien
  family: Lin
bibtex_author: Wang, Liangjun and Wang, Meixin
author:
- given: Liangjun
  family: Wang
- given: Meixin
  family: Wang
date: 2025-01-14
address:
container-title: Proceedings of the 16th Asian Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 14
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
