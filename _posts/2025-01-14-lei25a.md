---
title: Large Vision-Language Models as Emotion Recognizers in Context Awareness
booktitle: Proceedings of the 16th Asian Conference on Machine Learning
year: '2025'
volume: '260'
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: https://raw.githubusercontent.com/mlresearch/v260/main/assets/lei25a/lei25a.pdf
url: https://proceedings.mlr.press/v260/lei25a.html
openreview: Ns5aiol8ZD
abstract: 'Context-aware emotion recognition (CAER) is a complex and significant task
  that requires perceiving emotions from various contextual cues. Previous approaches
  primarily focus on designing sophisticated architectures to extract emotional cues
  from images. However, their knowledge is confined to specific training datasets
  and may reflect the subjective emotional biases of the annotators. Furthermore,
  acquiring large amounts of labeled data is often challenging in real-world applications.
  In this paper, we systematically explore the potential of leveraging Large Vision-Language
  Models (LVLMs) to empower the CAER task from three paradigms: 1) We fine-tune LVLMs
  on two CAER datasets, which is the most common way to transfer large models to downstream
  tasks. 2) We design zero-shot and few-shot patterns to evaluate the performance
  of LVLMs in scenarios with limited data or even completely unseen. In this case,
  a training-free framework is proposed to fully exploit the In-Context Learning (ICL)
  capabilities of LVLMs. Specifically, we develop an image similarity-based ranking
  algorithm to retrieve examples; subsequently, the instructions, retrieved examples,
  and the test example are combined to feed  LVLMs to obtain the corresponding sentiment
  judgment. 3) To leverage the rich knowledge base of LVLMs, we incorporate Chain-of-Thought
  (CoT) into our framework to enhance the modelâ€™s reasoning ability and provide interpretable
  results. Extensive experiments and analyses demonstrate that LVLMs achieve competitive
  performance in the CAER task across different paradigms. Notably, the superior performance
  in few-shot settings indicates the feasibility of LVLMs for accomplishing specific
  tasks without extensive training.'
layout: inproceedings
issn: 2640-3498
id: lei25a
tex_title: Large Vision-Language Models as Emotion Recognizers in Context Awareness
firstpage: 111
lastpage: 126
page: 111-126
order: 111
cycles: false
bibtex_editor: Nguyen, Vu and Lin, Hsuan-Tien
editor:
- given: Vu
  family: Nguyen
- given: Hsuan-Tien
  family: Lin
bibtex_author: Lei, Yuxuan and Yang, Dingkang and Chen, Zhaoyu and Chen, Jiawei and
  Zhai, Peng and Zhang, Lihua
author:
- given: Yuxuan
  family: Lei
- given: Dingkang
  family: Yang
- given: Zhaoyu
  family: Chen
- given: Jiawei
  family: Chen
- given: Peng
  family: Zhai
- given: Lihua
  family: Zhang
date: 2025-01-14
address:
container-title: Proceedings of the 16th Asian Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 14
extras:
- label: Supplementary PDF
  link: https://raw.githubusercontent.com/mlresearch/v260/main/assets/assets/lei25a/lei25a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
