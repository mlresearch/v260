---
title: Counterfacual Fairness for Graph Neural Networks with Limited and Privacy Protected
  Sensitive Attributes
booktitle: Proceedings of the 16th Asian Conference on Machine Learning
year: '2025'
volume: '260'
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: https://raw.githubusercontent.com/mlresearch/v260/main/assets/wang25e/wang25e.pdf
url: https://proceedings.mlr.press/v260/wang25e.html
openreview: R3ufV8D75Z
abstract: Graph Neural Networks (GNNs) have shown outstanding performance in learning
  graph representations, which increases their application in high-risk areas. However,
  GNNs may inherit biases from the graph data and make unfair predictions towards
  the protected sub-groups. To eliminate bias, a natural idea is to achieve counterfactual
  fairness from a causal perspective. Concretely, counterfactual fairness requires
  sufficient sensitive attributes as guidance, which is infeasible in the real world.
  The reason is that users with various privacy preferences may selectively publish
  their sensitive attributes and only limited sensitive attributes can be collected.
  Besides, the users who publish sensitive attributes still face privacy risks. In
  this paper, we first consider the situation in which the sensitive attributes are
  limited and propose a framework called PCFGR (Partially observed sensitive Attributes
  in Counterfactual Fair Graph Representation Learning) to learn fair graph representation
  from limited sensitive attributes. The framework trains a sensitive attribute estimator,
  which is applied to provide sufficient and accurate sensitive attributes. With these
  sensitive attributes, it can generate counterfactuals and eliminate the bias efficiently.
  Secondly, we aim to protect the privacy of the sensitive attributes and further
  propose PCFGR$\backslash$D. Specifically, PCFGR$\backslash$D first perturbs the
  sensitive attributes using Local Differential Privacy (LDP). Then it employs forward
  correction loss to train an accurate sensitive attributes estimator.  We conduct
  extensive experiments and the experiment results show that it outperforms other
  alternatives in balancing utility and fairness.
layout: inproceedings
issn: 2640-3498
id: wang25e
tex_title: Counterfacual Fairness for Graph Neural Networks with Limited and Privacy
  Protected Sensitive Attributes
firstpage: 719
lastpage: 734
page: 719-734
order: 719
cycles: false
bibtex_editor: Nguyen, Vu and Lin, Hsuan-Tien
editor:
- given: Vu
  family: Nguyen
- given: Hsuan-Tien
  family: Lin
bibtex_author: Wang, Xuemin and Wang, Lei and Gu, Tianlong and Bao, Xuguang
author:
- given: Xuemin
  family: Wang
- given: Lei
  family: Wang
- given: Tianlong
  family: Gu
- given: Xuguang
  family: Bao
date: 2025-01-14
address:
container-title: Proceedings of the 16th Asian Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 14
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
