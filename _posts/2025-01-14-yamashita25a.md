---
title: One-Shot Machine Unlearning with Mnemonic Code
booktitle: Proceedings of the 16th Asian Conference on Machine Learning
year: '2025'
volume: '260'
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: https://raw.githubusercontent.com/mlresearch/v260/main/assets/yamashita25a/yamashita25a.pdf
url: https://proceedings.mlr.press/v260/yamashita25a.html
software: https://github.com/tomyamkum/OneShotMU-with-MNCode
openreview: JQ7Ri3ccx6
abstract: "Ethical and privacy issues inherent in artificial intelligence (AI) applications
  have been a growing concern with the rapid spread of deep learning.\r Machine unlearning
  (MU) is the research area that addresses these issues by making a trained AI model
  forget about undesirable training data.\r Unfortunately, most existing MU methods
  incur significant time and computational costs for forgetting.\r Therefore, it is
  often difficult to apply these methods to practical datasets and sophisticated architectures,
  e.g., ImageNet and Transformer.\r To tackle this problem, we propose a lightweight
  and effective MU method.\r Our method identifies the model parameters sensitive
  to the forgetting targets and adds perturbation to such model parameters.\r We identify
  the sensitive parameters by calculating the Fisher Information Matrix (FIM).\r This
  approach does not require time-consuming additional training for forgetting.\r In
  addition, we introduce class-specific random signals called mnemonic code to reduce
  the cost of FIM calculation, which generally requires the entire training data and
  incurs significant computational costs.\r In our method, we train the model with
  mnemonic code; when forgetting, we use a small number of mnemonic codes to calculate
  the FIM and get the effective perturbation for forgetting.\r Comprehensive experiments
  demonstrate that our method is faster and better at forgetting than existing MU
  methods.\r Furthermore, we show that our method can scale to more practical datasets
  and sophisticated architectures."
layout: inproceedings
issn: 2640-3498
id: yamashita25a
tex_title: One-Shot Machine Unlearning with Mnemonic Code
firstpage: 255
lastpage: 270
page: 255-270
order: 255
cycles: false
bibtex_editor: Nguyen, Vu and Lin, Hsuan-Tien
editor:
- given: Vu
  family: Nguyen
- given: Hsuan-Tien
  family: Lin
bibtex_author: Yamashita, Tomoya and Yamada, Masanori and Shibata, Takashi
author:
- given: Tomoya
  family: Yamashita
- given: Masanori
  family: Yamada
- given: Takashi
  family: Shibata
date: 2025-01-14
address:
container-title: Proceedings of the 16th Asian Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 14
extras:
- label: Supplementary PDF
  link: https://raw.githubusercontent.com/mlresearch/v260/main/assets/assets/yamashita25a/yamashita25a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
