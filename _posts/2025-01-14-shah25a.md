---
title: Towards Calibrated Losses for Adversarial Robust Reject Option Classification
booktitle: Proceedings of the 16th Asian Conference on Machine Learning
year: '2025'
volume: '260'
series: Proceedings of Machine Learning Research
month: 0
publisher: PMLR
pdf: https://raw.githubusercontent.com/mlresearch/v260/main/assets/shah25a/shah25a.pdf
url: https://proceedings.mlr.press/v260/shah25a.html
software: https://github.com/Vrund0212/Calibrated-Losses-for-Adversarial-Robust-Reject-Option-Classification
openreview: lx046w4JHs
abstract: Robustness towards adversarial attacks is a vital property for classifiers
  in several applications such as autonomous driving, medical diagnosis, etc. Also,
  in such scenarios, where the cost of misclassification is very high, knowing when
  to abstain from prediction becomes crucial. A natural question is which surrogates
  can be used to ensure learning in scenarios where the input points are adversarially
  perturbed and the classifier can abstain from prediction? This paper aims to characterize
  and design surrogates calibrated in "Adversarial Robust Reject Option" setting.
  First, we propose an adversarial robust reject option loss $\ell_{d}^{\gamma}$ and
  analyze it for the hypothesis set of linear classifiers $\mathcal{H_\text{lin}}$.
  Next, we provide a complete characterization result for any surrogate to be $(\ell_{d}^{\gamma},\mathcal{H_{\text{lin}}})$-
  calibrated. To demonstrate the difficulty in designing surrogates to $\ell_{d}^{\gamma}$,
  we show negative calibration results for convex surrogates and quasi-concave conditional
  risk cases (these gave positive calibration in adversarial setting without reject
  option). We also empirically argue that Shifted Double Ramp Loss (DRL) and Shifted
  Double Sigmoid Loss (DSL) satisfy the calibration conditions. Finally, we demonstrate
  the robustness of shifted DRL and shifted DSL against adversarial perturbations
  on a synthetically generated dataset.
layout: inproceedings
issn: 2640-3498
id: shah25a
tex_title: Towards Calibrated Losses for Adversarial Robust Reject Option Classification
firstpage: 1256
lastpage: 1271
page: 1256-1271
order: 1256
cycles: false
bibtex_editor: Nguyen, Vu and Lin, Hsuan-Tien
editor:
- given: Vu
  family: Nguyen
- given: Hsuan-Tien
  family: Lin
bibtex_author: Shah, Vrund and Chaudhari, Tejas Kiran and Manwani, Naresh
author:
- given: Vrund
  family: Shah
- given: Tejas Kiran
  family: Chaudhari
- given: Naresh
  family: Manwani
date: 2025-01-14
address:
container-title: Proceedings of the 16th Asian Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 14
extras:
- label: Supplementary PDF
  link: https://raw.githubusercontent.com/mlresearch/v260/main/assets/assets/shah25a/shah25a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
